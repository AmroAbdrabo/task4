{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from pywt import wavedec\n",
    "from pywt import waverec\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import pywt\n",
    "import scipy\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "import pylab as pl\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Input, Add, Flatten, Concatenate, MaxPool1D, Conv1D, Bidirectional, LSTM, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg1 = pd.read_csv(\"train_eeg1.csv\").iloc[:, 1:]\n",
    "eeg2 = pd.read_csv(\"train_eeg2.csv\").iloc[:, 1:]\n",
    "emg = pd.read_csv(\"train_emg.csv\").iloc[:, 1:]\n",
    "df_y = pd.read_csv(\"train_labels.csv\").iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing by sampling with replacement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to pool all the under-represented REM 4-second signals together, then construct new examples as follows:\n",
    "\n",
    "1) For the 1st sample, randomly select a signal and choose its 1st sample as the newly constructed signal's 1st sample\n",
    "\n",
    "...\n",
    "\n",
    "512) For the 512th sample, randomly select a signal and choose its 512th sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg1np = eeg1.values\n",
    "eeg2np = eeg2.values\n",
    "emgnp = emg.values\n",
    "ynp = df_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "3553\n",
      "64800\n"
     ]
    }
   ],
   "source": [
    "#print(len(eeg2np[0])) 512\n",
    "#rem_indices = np.where(ynp == 3)[0]\n",
    "#print(len(rem_indices)) 3553\n",
    "#print(len(ynp))  64800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg1_aug = []\n",
    "eeg2_aug = []\n",
    "emg_aug  = []\n",
    "\n",
    "# approximately 6 percent of the total number of epochs, 64800, are REM in order to make them \n",
    "def samp_with_replacement(nbr_samples, class_lab):\n",
    "    class_idxs = np.where(ynp == class_lab)[0]\n",
    "    eeg1_f = eeg1np[class_idxs]\n",
    "    eeg2_f = eeg2np[class_idxs]\n",
    "    emg_f  = emgnp[class_idxs]\n",
    "    \n",
    "    # get the columns so we sample from them\n",
    "    eeg1np_t = eeg1_f.T   # has 512 rows\n",
    "    eeg2np_t = eeg2_f.T  # has 512 rows\n",
    "    emgnp_t = emg_f.T   # has 512 rows\n",
    "    \n",
    "    samples_eeg1 = np.array([[0]*512]*nbr_samples)\n",
    "    samples_eeg2 = np.array([[0]*512]*nbr_samples)\n",
    "    samples_emg =  np.array([[0]*512]*nbr_samples)\n",
    "    \n",
    "    for i in range(512):\n",
    "        samples_eeg1[:,i] = resample(eeg1np_t[i], replace=True, n_samples=nbr_samples, random_state=1)\n",
    "        samples_eeg2[:,i] = resample(eeg2np_t[i], replace=True, n_samples=nbr_samples, random_state=2)\n",
    "        samples_emg[:, i]  = resample(emgnp_t[i], replace=True,  n_samples=nbr_samples, random_state=3)\n",
    "    \n",
    "    global eeg1_aug, eeg2_aug, emg_aug\n",
    "    eeg1_aug = np.vstack((eeg1np, samples_eeg1))\n",
    "    eeg2_aug = np.vstack((eeg2np, samples_eeg2))\n",
    "    emg_aug  = np.vstack((emgnp, samples_emg))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_with_replacement(10000, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74800\n",
      "64800\n"
     ]
    }
   ],
   "source": [
    "#print(len(eeg1_aug)) 74800\n",
    "#print(len(eeg1np))  64800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Under-sample NREM and Wake classes\n",
    "According to https://arxiv.org/pdf/1809.08443.pdf, the rebalancing was done such that REM was roughly 25% (instead of 5% originally), NREM was 33% and finally 42% from Wake. This leads to the equations\n",
    "\n",
    "1) 13,553/(74,800 - x - y) = 0.25\n",
    "\n",
    "2) (27,133-y)/(74,800 - x - y) = 0.33\n",
    "\n",
    "3) (34,114-x)/(74,800 - x - y) = 0.42 (redundant)\n",
    "\n",
    "which leads to x = 11345 (i.e. reduce Wake by 11345 signals) and y = 9,243 which means Wake has now 22,769 signals, and NREM has 17,890 signals out of 54,212 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_aug = np.append(ynp, np.array([3]*10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74800, 1536)\n"
     ]
    }
   ],
   "source": [
    "under = RandomUnderSampler(sampling_strategy={1: 22769, 2:18890})   # technically this would give 34% for class NREM\n",
    "# stack them horizontally then unstack later by slicing\n",
    "X_new = np.hstack((eeg1_aug, eeg2_aug, emg_aug))\n",
    "print(X_new.shape)\n",
    "X_balanced, y_balanced = under.fit_resample(X_new, y_aug) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 20 seconds segments by combining 5 of the 4-second length segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55210\n"
     ]
    }
   ],
   "source": [
    "## split them again\n",
    "X_balanced = X_balanced[:-2, :]\n",
    "print(len(X_balanced)) # to make sure length is multiple of 5\n",
    "eeg1_bal = X_balanced[:, 0:512] \n",
    "eeg2_bal = X_balanced[:, 512:1024]\n",
    "emg_bal  = X_balanced[:, 1024:1536]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg1_reshaped = np.array([[0]*2560]*11042)\n",
    "eeg2_reshaped = np.array([[0]*2560]*11042)\n",
    "emg_reshaped = np.array([[0]*2560]*11042)\n",
    "for m in range(11042):  # 11,042 = 55210/5 minus since end will do m + 1 (may cause out of bounds exc.)\n",
    "    start = m*5\n",
    "    end = m*5 + 5\n",
    "    combined1 = ((eeg1_bal[start:end, :]).reshape(1, 2560))[0]\n",
    "    combined2 = ((eeg2_bal[start:end, :]).reshape(1, 2560))[0]\n",
    "    combined3 = ((emg_bal[start:end, :]).reshape(1, 2560))[0]\n",
    "    eeg1_reshaped[m] = combined1\n",
    "    eeg2_reshaped[m] = combined2\n",
    "    emg_reshaped[m] = combined3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMS filter of the EMG signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_rms(a, window_size):\n",
    "  a2 = np.power(a,2)\n",
    "  window = 1.0*np.ones(window_size)\n",
    "  return np.sqrt(np.convolve(a2, window, 'valid'))/float(window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11042, 2560)\n"
     ]
    }
   ],
   "source": [
    "#rms_vals = np.array([[0]*20]*11042)    # window size is 1 second = 128 samples in each window\n",
    "print(emg_reshaped.shape)\n",
    "def rms_transform(row):\n",
    "    res = np.array([])\n",
    "    end = len(row)\n",
    "    for i in range(end - 128):\n",
    "        window = row[i:(i + 128)]\n",
    "        temp = window_rms(window, 128)\n",
    "        res = np.append(res, temp)\n",
    "    return res\n",
    "rms_vals= np.apply_along_axis(rms_transform, axis = 1, arr = emg_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11042, 2432)\n"
     ]
    }
   ],
   "source": [
    "print(rms_vals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11042, 20)\n"
     ]
    }
   ],
   "source": [
    "# this cell is not needed anymore\n",
    "# for some reason there is a third dimension, to remove it:\n",
    "#rms_vals = rms_vals[:, :, 0]\n",
    "#print(rms_vals.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine EEG channels\n",
    "so the rows of a matrix are actually two arrays corresponding to EEG1 and EEG2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11042, 5120)\n",
      "(11042, 2560, 2)\n"
     ]
    }
   ],
   "source": [
    "eegs_comb = np.hstack((eeg1_reshaped, eeg2_reshaped))\n",
    "print(eegs_comb.shape)\n",
    "def combine_channels(signals):\n",
    "    sigs = np.split(signals, 2)\n",
    "    eeg1 = sigs[0]\n",
    "    eeg2 = sigs[1]\n",
    "    return np.array((eeg1, eeg2)).T\n",
    "    \n",
    "channels = np.apply_along_axis(combine_channels, axis = 1, arr = eegs_comb)\n",
    "print(channels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction - Model left branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 13, 128)\n"
     ]
    }
   ],
   "source": [
    "def left_branch_model():\n",
    "    signal = Input(shape = (2560, 2))\n",
    "    x = Conv1D(filters = 64, kernel_size = 50,  strides = 6, activation='relu')(signal)\n",
    "    x = MaxPool1D(pool_size=8, strides=8)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 8, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 8, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 8, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = MaxPool1D(pool_size=4, strides=4)(x)\n",
    "    print(x.shape)\n",
    "    return tf.keras.Model(inputs = signal, outputs = x)\n",
    "lbranch = left_branch_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction - Model middle branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 3, 128)\n"
     ]
    }
   ],
   "source": [
    "def mid_branch_model():\n",
    "    signal = Input(shape = (2560, 2))\n",
    "    x = Conv1D(filters = 64, kernel_size = 500,  strides = 50, activation='relu', padding = 'same')(signal) # try with and without padding = 'same'\n",
    "    x = MaxPool1D(pool_size=8, strides=8)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = MaxPool1D(pool_size=2, strides=2)(x)\n",
    "    print(x.shape)\n",
    "    return tf.keras.Model(inputs = signal, outputs = x)\n",
    "mbranch = mid_branch_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction - Model right branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 6, 128)\n"
     ]
    }
   ],
   "source": [
    "def right_branch_model():\n",
    "    signal = Input(shape=(2432, 1))\n",
    "    z = Conv1D(filters = 64, kernel_size = 500,  strides = 50, activation='relu', padding = 'same')(signal)\n",
    "    z = MaxPool1D(pool_size=4, strides=4)(z)\n",
    "    z = Dropout(0.5)(z)\n",
    "    z = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(z)\n",
    "    z = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(z)\n",
    "    z = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(z)\n",
    "    z = MaxPool1D(pool_size=2, strides=2)(z)\n",
    "    print(z.shape)\n",
    "    return tf.keras.Model(inputs = signal, outputs = z)\n",
    "rbranch = right_branch_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate along the second dimension (of sizes 13, 3, 6 respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_layer = Concatenate(axis = 1)([lbranch.output, mbranch.output, rbranch.output])\n",
    "concat_model = tf.keras.Model(inputs = [lbranch.input, mbranch.input, rbranch.input], outputs = concat_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1024)\n",
      "(None, 1024)\n",
      "(None, 1024)\n"
     ]
    }
   ],
   "source": [
    "s = Dropout(0.5)(inputs = concat_model.output)\n",
    "\n",
    "# Left branch (cannot flatten before since LSTM requires input of form (None, x, y) NOT (None, z))\n",
    "sLeft = Bidirectional(LSTM(units = 512, return_sequences = True, activation='tanh'))(s) #https://stackoverflow.com/questions/40331510/how-to-stack-multiple-lstm-in-keras\n",
    "sLeft = Bidirectional(LSTM(units = 512, activation='tanh'))(sLeft)\n",
    "print(sLeft.shape)\n",
    "\n",
    "# Right branch\n",
    "q = Flatten()(s)\n",
    "q = Dense(units = 1024, activation = 'relu')(q)\n",
    "print(q.shape)\n",
    "\n",
    "# combine both 1024-length vectors by adding them\n",
    "q = Add()([q, sLeft])\n",
    "print(q.shape)\n",
    "\n",
    "# now dropout at "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 10, 64)\n",
      "(None, 5, 128)\n",
      "(None, 5, 128)\n",
      "(None, 2432, 1)\n",
      "(None, 39, 64)\n",
      "(None, 9, 64)\n",
      "(None, 9, 64)\n",
      "(None, 4, 128)\n",
      "(None, 8, 64)\n",
      "(None, 3, 128)\n",
      "(None, 6, 64)\n",
      "(None, 1, 128)\n",
      "(None, 1, 64)\n",
      "(None, 19, 64)\n",
      "(None, 1024)\n",
      "q4 has shape (None, 1024)\n",
      "q3 has shape (None, 1024)\n",
      "(None, 3)\n"
     ]
    }
   ],
   "source": [
    "#Left most CNN\n",
    "signal1 = Input(shape=(2560, 2))\n",
    "x = Conv1D(filters = 64, kernel_size = 50,  strides = 6, activation='relu')(signal1)\n",
    "x = MaxPool1D(pool_size=8, strides=8)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Conv1D(filters = 128, kernel_size = 8, strides = 1, activation = 'relu')(x)\n",
    "x = Conv1D(filters = 128, kernel_size = 8, strides = 1, activation = 'relu')(x)\n",
    "x = Conv1D(filters = 128, kernel_size = 8, strides = 1, activation = 'relu')(x)\n",
    "x = MaxPool1D(pool_size=4, strides=4)(x)\n",
    "x = Reshape((14, 64))(x)\n",
    "\n",
    "#Middle most CNN\n",
    "signal2 = Input(shape=(2560, 2))\n",
    "y = Conv1D(filters = 64, kernel_size = 500, strides = 50, activation='relu')(signal2)\n",
    "y = MaxPool1D(pool_size=4, strides=4)(y)\n",
    "y = Dropout(0.5)(y)\n",
    "print(y.shape)\n",
    "y = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu')(y)\n",
    "print(y.shape)\n",
    "y = Reshape((10, 64))(y)\n",
    "y = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu')(y)\n",
    "print(y.shape)\n",
    "y = Reshape((10, 64))(y)\n",
    "y = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu')(y)\n",
    "y = MaxPool1D(pool_size=2, strides=2)(y)\n",
    "y = Reshape((4, 64))(y)\n",
    "\n",
    "#Right CNN\n",
    "signal_emg = Input(shape=(2432, 1))\n",
    "print(signal_emg.shape)\n",
    "z = Conv1D(filters = 64, kernel_size = 500,  strides = 50, activation='relu')(signal_emg)\n",
    "print(z.shape)\n",
    "z = MaxPool1D(pool_size=4, strides=4)(z)\n",
    "print(z.shape)\n",
    "z = Dropout(0.5)(z)\n",
    "print(z.shape)\n",
    "z = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'valid')(z)\n",
    "print(z.shape)\n",
    "z = Reshape((8, 64))(z)\n",
    "#print('**************')\n",
    "print(z.shape)\n",
    "z = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'valid')(z)\n",
    "print(z.shape)\n",
    "z = Reshape((6, 64))(z)\n",
    "print(z.shape)\n",
    "z = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'valid')(z)\n",
    "print(z.shape)\n",
    "z = Reshape((2, 64))(z)\n",
    "z = MaxPool1D(pool_size=2, strides=2)(z)\n",
    "print(z.shape)\n",
    "\n",
    "prelim_model = Concatenate(axis = 1)([x, y, z])  # NOT sure at all if I should flatten before concatenation instead of doing axis = 1\n",
    "p2 = Dropout(0.5)(prelim_model)\n",
    "print(p2.shape)\n",
    "p3 = Bidirectional(LSTM(units = 512, activation='tanh'))(p2)\n",
    "print(p3.shape)\n",
    "p3 = Reshape((16, 64))(p3)\n",
    "p4 = Bidirectional(LSTM(units = 512, activation='tanh'))(p3)\n",
    "\n",
    "q2 = Flatten()(p2)\n",
    "q3 = Dense(units = 1024, activation = 'relu')(q2)\n",
    "q3 = Flatten()(q3)\n",
    "q4 = Flatten()(p4)\n",
    "print(\"q4 has shape \"+ str(q4.shape))\n",
    "print(\"q3 has shape \"+ str(q3.shape))\n",
    "\n",
    "out = Add()([q3, q4])\n",
    "out = Dropout(0.5)(q5)\n",
    "print(out.shape)\n",
    "out = Dense(3, activation='softmax')(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([signal1, signal2, signal_emg], out)\n",
    "print(model.summary())\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "X = [np.zeros((1,27,27,1))] * 2\n",
    "y = np.ones((1,1))\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         x1        x2        x3       x4        x5       x6        x7  \\\n",
      "0  0.000400  0.000470  0.000067 -0.00016 -0.000003  0.00031  0.000360   \n",
      "1  0.000067  0.000095  0.000270  0.00028  0.000250  0.00012  0.000094   \n",
      "2  0.000160 -0.000210 -0.000840 -0.00120 -0.001200 -0.00140 -0.001400   \n",
      "3 -0.000140  0.000260  0.000390  0.00043  0.000280  0.00023  0.000390   \n",
      "4 -0.001100 -0.000790 -0.000081  0.00014  0.000200 -0.00014 -0.000430   \n",
      "\n",
      "        x8        x9      x10  ...      x503      x504      x505      x506  \\\n",
      "0  0.00019 -0.000072 -0.00007  ... -0.000086  0.000033 -0.000046 -0.000270   \n",
      "1 -0.00034 -0.000960 -0.00120  ...  0.000046  0.000300  0.000630  0.000710   \n",
      "2 -0.00091 -0.000600 -0.00027  ... -0.000680 -0.000880 -0.001000 -0.000770   \n",
      "3  0.00022  0.000150  0.00022  ...  0.000720  0.000760  0.000380  0.000052   \n",
      "4 -0.00053 -0.000580 -0.00041  ...  0.000290  0.000600  0.000670  0.000190   \n",
      "\n",
      "       x507     x508     x509     x510      x511      x512  \n",
      "0 -0.000390 -0.00034 -0.00032 -0.00021  0.000042  0.000053  \n",
      "1  0.000520  0.00041  0.00066  0.00088  0.000770  0.000410  \n",
      "2 -0.000680 -0.00073 -0.00073 -0.00062 -0.000550 -0.000540  \n",
      "3 -0.000260 -0.00058 -0.00075 -0.00110 -0.001200 -0.001200  \n",
      "4 -0.000055 -0.00016 -0.00023 -0.00023 -0.000330 -0.000810  \n",
      "\n",
      "[5 rows x 512 columns]\n"
     ]
    }
   ],
   "source": [
    "print(eeg1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
