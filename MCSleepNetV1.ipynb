{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this revised version, we will be using class weights as done in https://www.tensorflow.org/tutorials/structured_data/imbalanced_data we will also do transfer learning as was mentioned in the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from pywt import wavedec\n",
    "from pywt import waverec\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from keras.utils import to_categorical\n",
    "import pywt\n",
    "import scipy\n",
    "#from keras.utils import plot_model #plot_model(model, to_file='model.png')\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "import pylab as pl\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Input, Add, Flatten, Concatenate, MaxPool1D, Conv1D, Bidirectional, LSTM, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg1 = pd.read_csv(\"train_eeg1.csv\").iloc[:, 1:]\n",
    "eeg2 = pd.read_csv(\"train_eeg2.csv\").iloc[:, 1:]\n",
    "emg  = pd.read_csv(\"train_emg.csv\").iloc[:, 1:]\n",
    "df_y = pd.read_csv(\"train_labels.csv\").iloc[:, 1:]\n",
    "\n",
    "eeg1_t = pd.read_csv(\"test_eeg1.csv\").iloc[:, 1:]\n",
    "eeg2_t = pd.read_csv(\"test_eeg2.csv\").iloc[:, 1:]\n",
    "emg_t = pd.read_csv(\"test_emg.csv\").iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 20 seconds segments by combining 5 of the 4-second length segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split them again\n",
    "eeg1v = eeg1.values\n",
    "eeg2v = eeg2.values\n",
    "emgv = emg.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12960\n"
     ]
    }
   ],
   "source": [
    "print(len(eeg1v)//5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12960, 2560)\n",
      "(12960, 2560)\n",
      "(12960, 2560)\n"
     ]
    }
   ],
   "source": [
    "def reshape_sig(eeg1v, eeg2v, emgv):\n",
    "    new_len = len(emgv)//5\n",
    "    eeg1_reshaped = np.array([[0]*2560]*new_len)\n",
    "    eeg2_reshaped = np.array([[0]*2560]*new_len)\n",
    "    emg_reshaped = np.array([[0]*2560]*new_len)\n",
    "    for i in range(new_len):  # 11,042 = 55210/5 minus since end will do m + 1 (may cause out of bounds exc.)\n",
    "        start = i*5\n",
    "        end = i*5 + 5\n",
    "        combined1 = ((eeg1v[start:end, :]).reshape(1, 2560))[0]\n",
    "        combined2 = ((eeg2v[start:end, :]).reshape(1, 2560))[0]\n",
    "        combined3 = ((emgv[start:end, :]).reshape(1, 2560))[0]\n",
    "        eeg1_reshaped[i] = combined1\n",
    "        eeg2_reshaped[i] = combined2\n",
    "        emg_reshaped[i] = combined3\n",
    "    return (eeg1_reshaped, eeg2_reshaped, emg_reshaped)\n",
    "\n",
    "eeg1_reshaped, eeg2_reshaped, emg_reshaped = reshape_sig(eeg1v, eeg2v, emgv)\n",
    "print(eeg1_reshaped.shape)\n",
    "print(eeg2_reshaped.shape)\n",
    "print(emg_reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMS filter of the EMG signal (applied over a second = 128 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_rms(a, window_size):\n",
    "  a2 = np.power(a,2)\n",
    "  window = 1.0*np.ones(window_size)\n",
    "  return np.sqrt(np.convolve(a2, window, 'valid'))/float(window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12960, 2560)\n"
     ]
    }
   ],
   "source": [
    "print(emg_reshaped.shape)\n",
    "def rms_transform(row):\n",
    "    res = np.array([])\n",
    "    end = len(row)\n",
    "    for i in range(end - 128):\n",
    "        window = row[i:(i + 128)]\n",
    "        temp = window_rms(window, 128)\n",
    "        res = np.append(res, temp)\n",
    "    return res\n",
    "rms_vals= np.apply_along_axis(rms_transform, axis = 1, arr = emg_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12960, 2432)\n"
     ]
    }
   ],
   "source": [
    "print(rms_vals.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine EEG channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12960, 5120)\n",
      "(12960, 2560, 2)\n"
     ]
    }
   ],
   "source": [
    "eegs_comb = np.hstack((eeg1_reshaped, eeg2_reshaped))\n",
    "print(eegs_comb.shape)\n",
    "def combine_channels(signals):\n",
    "    sigs = np.split(signals, 2)\n",
    "    eeg1 = sigs[0]\n",
    "    eeg2 = sigs[1]\n",
    "    return np.array((eeg1, eeg2)).T\n",
    "    \n",
    "channels = np.apply_along_axis(combine_channels, axis = 1, arr = eegs_comb)\n",
    "print(channels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 13, 128)\n"
     ]
    }
   ],
   "source": [
    "signal_left = Input(shape = (2560, 2), name=\"left_signal\")\n",
    "def left_branch_model():\n",
    "    x = Conv1D(filters = 64, kernel_size = 50,  strides = 6, activation='relu')(signal_left)\n",
    "    x = MaxPool1D(pool_size=8, strides=8)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 8, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 8, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 8, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = MaxPool1D(pool_size=4, strides=4)(x)\n",
    "    print(x.shape)\n",
    "    return x #tf.keras.Model(inputs = signal, outputs = x)\n",
    "lbranch = left_branch_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 3, 128)\n"
     ]
    }
   ],
   "source": [
    "signal_mid = Input(shape = (2560, 2), name=\"mid_signal\")\n",
    "def mid_branch_model():\n",
    "    x = Conv1D(filters = 64, kernel_size = 500,  strides = 50, activation='relu', padding = 'same')(signal_mid) # try with and without padding = 'same'\n",
    "    x = MaxPool1D(pool_size=8, strides=8)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = MaxPool1D(pool_size=2, strides=2)(x)\n",
    "    print(x.shape)\n",
    "    return x #tf.keras.Model(inputs = signal, outputs = x)\n",
    "mbranch = mid_branch_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 6, 128)\n"
     ]
    }
   ],
   "source": [
    "signal_right = Input(shape=(2432, 1),  name=\"right_signal\")\n",
    "def right_branch_model():\n",
    "    z = Conv1D(filters = 64, kernel_size = 500,  strides = 50, activation='relu', padding = 'same')(signal_right)\n",
    "    z = MaxPool1D(pool_size=4, strides=4)(z)\n",
    "    z = Dropout(0.5)(z)\n",
    "    z = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(z)\n",
    "    z = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(z)\n",
    "    z = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(z)\n",
    "    z = MaxPool1D(pool_size=2, strides=2)(z)\n",
    "    print(z.shape)\n",
    "    return z #tf.keras.Model(inputs = signal, outputs = z)\n",
    "rbranch = right_branch_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 22, 128)\n"
     ]
    }
   ],
   "source": [
    "concat_layer = Concatenate(axis = 1, name = 'concat_axis')([lbranch, mbranch, rbranch])\n",
    "print(concat_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_signal\n",
      "mid_signal\n",
      "right_signal\n",
      "conv1d_24\n",
      "conv1d_28\n",
      "conv1d_32\n",
      "max_pooling1d_12\n",
      "max_pooling1d_14\n",
      "max_pooling1d_16\n",
      "dropout_12\n",
      "dropout_13\n",
      "dropout_14\n",
      "conv1d_25\n",
      "conv1d_29\n",
      "conv1d_33\n",
      "conv1d_26\n",
      "conv1d_30\n",
      "conv1d_34\n",
      "conv1d_27\n",
      "conv1d_31\n",
      "conv1d_35\n",
      "max_pooling1d_13\n",
      "max_pooling1d_15\n",
      "max_pooling1d_17\n",
      "concat_axis\n",
      "flatten_3\n",
      "dense_8\n"
     ]
    }
   ],
   "source": [
    "pre_trained_fc = Flatten()(concat_layer)\n",
    "pre_trained_fc = Dense(3, activation = 'softmax')(pre_trained_fc)\n",
    "pre_trained_model = tf.keras.Model(inputs = [signal_left, signal_mid, signal_right], outputs = pre_trained_fc)\n",
    "for el in pre_trained_model.layers:\n",
    "    print(el.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1024)\n",
      "(None, 1024)\n",
      "(None, 1024)\n"
     ]
    }
   ],
   "source": [
    "# SCORING BEGINS HERE (but is not used until later)\n",
    "s = Dropout(0.5)(concat_layer)\n",
    "\n",
    "# Left branch (cannot flatten before since LSTM requires input of form (None, x, y) NOT (None, z))\n",
    "sLeft = Bidirectional(LSTM(units = 512, return_sequences = True, activation='tanh'))(s) #https://stackoverflow.com/questions/40331510/how-to-stack-multiple-lstm-in-keras\n",
    "sLeft = Bidirectional(LSTM(units = 512, activation='tanh'))(sLeft)\n",
    "print(sLeft.shape)\n",
    "\n",
    "# Right branch\n",
    "q = Flatten()(s)\n",
    "q = Dense(units = 1024, activation = 'relu')(q)\n",
    "print(q.shape)\n",
    "\n",
    "# combine both 1024-length vectors by adding them\n",
    "q = Add()([q, sLeft])\n",
    "print(q.shape)\n",
    "\n",
    "# now dropout 50% and softmax on 3 output neurons\n",
    "q = Dropout(0.5)(q)\n",
    "q = Dense(3, activation = 'softmax')(q)\n",
    "\n",
    "model = tf.keras.Model(inputs = [signal_left, signal_mid, signal_right], outputs = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64800, 1)\n"
     ]
    }
   ],
   "source": [
    "# one hot encode the labels\n",
    "y = (df_y.values) - 1\n",
    "print(y.shape)\n",
    "y_encoded = to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut off last mouse subject from the data to use for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4320\n"
     ]
    }
   ],
   "source": [
    "len_to_cut = len(channels)//3\n",
    "print(len_to_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8640\n",
      "8640\n"
     ]
    }
   ],
   "source": [
    "len_to_keep = len(channels)- len_to_cut\n",
    "train_channels = channels[0:len_to_keep]\n",
    "cv_channels = channels[len_to_keep:]\n",
    "train_emg = rms_vals[0:len_to_keep]\n",
    "cv_emg = rms_vals[len_to_keep:]\n",
    "print(len(train_channels))\n",
    "print(len(train_emg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8640\n",
      "8640\n"
     ]
    }
   ],
   "source": [
    "# now its time to train the pre_trained model, save it, pop the last layer off (the dense one)\n",
    "# shuffle the data\n",
    "len_channels = np.arange(0, len(train_channels))\n",
    "np.random.shuffle(len_channels)\n",
    "train_sh_emg = train_emg[len_channels]\n",
    "train_sh_channels = train_channels[len_channels]\n",
    "print(len(train_sh_emg))\n",
    "print(len(train_sh_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64800, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64800\n"
     ]
    }
   ],
   "source": [
    "print(len(y_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "new_len = len(y_encoded)//5\n",
    "y_train = np.array([[0]*3]*new_len)\n",
    "for i in range(new_len):\n",
    "    idx= i*5\n",
    "    select_mid = idx+2 #(select the middle of the 5 4-second epochs as the label)\n",
    "    y_train[i] = y_encoded[select_mid]\n",
    "    \n",
    "print(y_train[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_encoded[4:34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12960\n",
      "8640\n"
     ]
    }
   ],
   "source": [
    "y_train_new = y_train[0: len_to_keep]\n",
    "y_cv = y_train[len_to_keep:]\n",
    "y_train_new = y_train_new[len_channels]\n",
    "print(len(y_train))\n",
    "print(len(y_train_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the pre_trained model\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "pre_trained_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "87/87 [==============================] - 16s 182ms/step - loss: 1.0964 - accuracy: 0.5341\n",
      "Epoch 2/10\n",
      "87/87 [==============================] - 16s 179ms/step - loss: 1.0920 - accuracy: 0.5341\n",
      "Epoch 3/10\n",
      "87/87 [==============================] - 16s 179ms/step - loss: 1.0877 - accuracy: 0.5341\n",
      "Epoch 4/10\n",
      "87/87 [==============================] - 16s 179ms/step - loss: 1.0835 - accuracy: 0.5341\n",
      "Epoch 5/10\n",
      "87/87 [==============================] - 16s 180ms/step - loss: 1.0793 - accuracy: 0.5341\n",
      "Epoch 6/10\n",
      "87/87 [==============================] - 16s 183ms/step - loss: 1.0753 - accuracy: 0.5341\n",
      "Epoch 7/10\n",
      "68/87 [======================>.......] - ETA: 3s - loss: 1.0717 - accuracy: 0.5287"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-b71e290da2aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpre_trained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"left_signal\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_sh_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mid_signal\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_sh_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"right_signal\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_sh_emg\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = pre_trained_model.fit({\"left_signal\": train_sh_channels, \"mid_signal\": train_sh_channels, \"right_signal\": train_sh_emg}, y_train_new, batch_size = 100, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8640, 2560, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_sh_channels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8640, 2432)\n"
     ]
    }
   ],
   "source": [
    "print(train_sh_emg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
