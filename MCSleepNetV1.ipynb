{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this revised version, we will be using class weights as done in https://www.tensorflow.org/tutorials/structured_data/imbalanced_data we will also do transfer learning as was mentioned in the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from pywt import wavedec\n",
    "from pywt import waverec\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from keras.utils import to_categorical\n",
    "import pywt\n",
    "import scipy\n",
    "#from keras.utils import plot_model #plot_model(model, to_file='model.png')\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "import pylab as pl\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Input, Add, Flatten, Concatenate, MaxPool1D, Conv1D, Bidirectional, LSTM, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg1 = pd.read_csv(\"train_eeg1.csv\").iloc[:, 1:]\n",
    "eeg2 = pd.read_csv(\"train_eeg2.csv\").iloc[:, 1:]\n",
    "emg  = pd.read_csv(\"train_emg.csv\").iloc[:, 1:]\n",
    "df_y = pd.read_csv(\"train_labels.csv\").iloc[:, 1:]\n",
    "\n",
    "eeg1_t = pd.read_csv(\"test_eeg1.csv\").iloc[:, 1:]\n",
    "eeg2_t = pd.read_csv(\"test_eeg2.csv\").iloc[:, 1:]\n",
    "emg_t = pd.read_csv(\"test_emg.csv\").iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 20 seconds segments by combining 5 of the 4-second length segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split them again\n",
    "eeg1v = eeg1.values\n",
    "eeg2v = eeg2.values\n",
    "emgv = emg.values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12960\n"
     ]
    }
   ],
   "source": [
    "print(len(eeg1v)//5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12960, 2560)\n",
      "(12960, 2560)\n",
      "(12960, 2560)\n"
     ]
    }
   ],
   "source": [
    "def reshape_sig(eeg1v, eeg2v, emgv):\n",
    "    new_len = len(emgv)//5\n",
    "    eeg1_reshaped = np.array([[0]*2560]*new_len)\n",
    "    eeg2_reshaped = np.array([[0]*2560]*new_len)\n",
    "    emg_reshaped = np.array([[0]*2560]*new_len)\n",
    "    for i in range(new_len):  # 11,042 = 55210/5 minus since end will do m + 1 (may cause out of bounds exc.)\n",
    "        start = i*5\n",
    "        end = i*5 + 5\n",
    "        combined1 = ((eeg1v[start:end, :]).reshape(1, 2560))[0]\n",
    "        combined2 = ((eeg2v[start:end, :]).reshape(1, 2560))[0]\n",
    "        combined3 = ((emgv[start:end, :]).reshape(1, 2560))[0]\n",
    "        eeg1_reshaped[i] = combined1\n",
    "        eeg2_reshaped[i] = combined2\n",
    "        emg_reshaped[i] = combined3\n",
    "    return (eeg1_reshaped, eeg2_reshaped, emg_reshaped)\n",
    "\n",
    "eeg1_reshaped, eeg2_reshaped, emg_reshaped = reshape_sig(eeg1v, eeg2v, emgv)\n",
    "print(eeg1_reshaped.shape)\n",
    "print(eeg2_reshaped.shape)\n",
    "print(emg_reshaped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMS filter of the EMG signal (applied over a second = 128 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_rms(a, window_size):\n",
    "  a2 = np.power(a,2)\n",
    "  window = 1.0*np.ones(window_size)\n",
    "  return np.sqrt(np.convolve(a2, window, 'valid'))/float(window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12960, 2560)\n"
     ]
    }
   ],
   "source": [
    "print(emg_reshaped.shape)\n",
    "def rms_transform(row):\n",
    "    res = np.array([])\n",
    "    end = len(row)\n",
    "    for i in range(end - 128):\n",
    "        window = row[i:(i + 128)]\n",
    "        temp = window_rms(window, 128)\n",
    "        res = np.append(res, temp)\n",
    "    return res\n",
    "rms_vals= np.apply_along_axis(rms_transform, axis = 1, arr = emg_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12960, 2432)\n"
     ]
    }
   ],
   "source": [
    "print(rms_vals.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine EEG channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12960, 5120)\n",
      "(12960, 2560, 2)\n"
     ]
    }
   ],
   "source": [
    "eegs_comb = np.hstack((eeg1_reshaped, eeg2_reshaped))\n",
    "print(eegs_comb.shape)\n",
    "def combine_channels(signals):\n",
    "    sigs = np.split(signals, 2)\n",
    "    eeg1 = sigs[0]\n",
    "    eeg2 = sigs[1]\n",
    "    return np.array((eeg1, eeg2)).T\n",
    "    \n",
    "channels = np.apply_along_axis(combine_channels, axis = 1, arr = eegs_comb)\n",
    "print(channels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 13, 128)\n"
     ]
    }
   ],
   "source": [
    "signal_left = Input(shape = (2560, 2), name=\"left_signal\")\n",
    "def left_branch_model():\n",
    "    x = Conv1D(filters = 64, kernel_size = 50,  strides = 6, activation='relu')(signal_left)\n",
    "    x = MaxPool1D(pool_size=8, strides=8)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 8, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 8, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 8, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = MaxPool1D(pool_size=4, strides=4)(x)\n",
    "    print(x.shape)\n",
    "    return x #tf.keras.Model(inputs = signal, outputs = x)\n",
    "lbranch = left_branch_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 3, 128)\n"
     ]
    }
   ],
   "source": [
    "signal_mid = Input(shape = (2560, 2), name=\"mid_signal\")\n",
    "def mid_branch_model():\n",
    "    x = Conv1D(filters = 64, kernel_size = 500,  strides = 50, activation='relu', padding = 'same')(signal_mid) # try with and without padding = 'same'\n",
    "    x = MaxPool1D(pool_size=8, strides=8)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = MaxPool1D(pool_size=2, strides=2)(x)\n",
    "    print(x.shape)\n",
    "    return x #tf.keras.Model(inputs = signal, outputs = x)\n",
    "mbranch = mid_branch_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 6, 128)\n"
     ]
    }
   ],
   "source": [
    "signal_right = Input(shape=(2432, 1),  name=\"right_signal\")\n",
    "def right_branch_model():\n",
    "    z = Conv1D(filters = 64, kernel_size = 500,  strides = 50, activation='relu', padding = 'same')(signal_right)\n",
    "    z = MaxPool1D(pool_size=4, strides=4)(z)\n",
    "    z = Dropout(0.5)(z)\n",
    "    z = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(z)\n",
    "    z = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(z)\n",
    "    z = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(z)\n",
    "    z = MaxPool1D(pool_size=2, strides=2)(z)\n",
    "    print(z.shape)\n",
    "    return z #tf.keras.Model(inputs = signal, outputs = z)\n",
    "rbranch = right_branch_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 22, 128)\n"
     ]
    }
   ],
   "source": [
    "concat_layer = Concatenate(axis = 1, name = 'concat_axis')([lbranch, mbranch, rbranch])\n",
    "print(concat_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_signal\n",
      "mid_signal\n",
      "right_signal\n",
      "conv1d_36\n",
      "conv1d_40\n",
      "conv1d_44\n",
      "max_pooling1d_18\n",
      "max_pooling1d_20\n",
      "max_pooling1d_22\n",
      "dropout_19\n",
      "dropout_20\n",
      "dropout_21\n",
      "conv1d_37\n",
      "conv1d_41\n",
      "conv1d_45\n",
      "conv1d_38\n",
      "conv1d_42\n",
      "conv1d_46\n",
      "conv1d_39\n",
      "conv1d_43\n",
      "conv1d_47\n",
      "max_pooling1d_19\n",
      "max_pooling1d_21\n",
      "max_pooling1d_23\n",
      "concat_axis\n",
      "flatten_6\n",
      "dense_13\n"
     ]
    }
   ],
   "source": [
    "pre_trained_fc = Flatten()(concat_layer)\n",
    "pre_trained_fc = Dense(3, activation = 'softmax')(pre_trained_fc)\n",
    "pre_trained_model = tf.keras.Model(inputs = [signal_left, signal_mid, signal_right], outputs = pre_trained_fc)\n",
    "for el in pre_trained_model.layers:\n",
    "    print(el.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1024)\n",
      "(None, 1024)\n",
      "(None, 1024)\n"
     ]
    }
   ],
   "source": [
    "# SCORING BEGINS HERE (but is not used until later)\n",
    "s = Dropout(0.5)(concat_layer)\n",
    "\n",
    "# Left branch (cannot flatten before since LSTM requires input of form (None, x, y) NOT (None, z))\n",
    "sLeft = Bidirectional(LSTM(units = 512, return_sequences = True, activation='tanh'))(s) #https://stackoverflow.com/questions/40331510/how-to-stack-multiple-lstm-in-keras\n",
    "sLeft = Bidirectional(LSTM(units = 512, activation='tanh'))(sLeft)\n",
    "print(sLeft.shape)\n",
    "\n",
    "# Right branch\n",
    "q = Flatten()(s)\n",
    "q = Dense(units = 1024, activation = 'relu')(q)\n",
    "print(q.shape)\n",
    "\n",
    "# combine both 1024-length vectors by adding them\n",
    "q = Add()([q, sLeft])\n",
    "print(q.shape)\n",
    "\n",
    "# now dropout 50% and softmax on 3 output neurons\n",
    "q = Dropout(0.5)(q)\n",
    "q = Dense(3, activation = 'softmax')(q)\n",
    "\n",
    "model = tf.keras.Model(inputs = [signal_left, signal_mid, signal_right], outputs = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64800, 1)\n"
     ]
    }
   ],
   "source": [
    "# one hot encode the labels\n",
    "y = (df_y.values) - 1\n",
    "print(y.shape)\n",
    "y_encoded = to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut off last mouse subject from the data to use for cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4320\n"
     ]
    }
   ],
   "source": [
    "len_to_cut = len(channels)//3\n",
    "print(len_to_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8640\n",
      "8640\n"
     ]
    }
   ],
   "source": [
    "len_to_keep = len(channels)- len_to_cut\n",
    "train_channels = channels[0:len_to_keep]\n",
    "cv_channels = channels[len_to_keep:]\n",
    "train_emg = rms_vals[0:len_to_keep]\n",
    "cv_emg = rms_vals[len_to_keep:]\n",
    "print(len(train_channels))\n",
    "print(len(train_emg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8640\n",
      "8640\n"
     ]
    }
   ],
   "source": [
    "# now its time to train the pre_trained model, save it, pop the last layer off (the dense one)\n",
    "# shuffle the data\n",
    "len_channels = np.arange(0, len(train_channels))\n",
    "np.random.shuffle(len_channels)\n",
    "train_sh_emg = train_emg[len_channels]\n",
    "train_sh_channels = train_channels[len_channels]\n",
    "print(len(train_sh_emg))\n",
    "print(len(train_sh_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64800, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64800\n"
     ]
    }
   ],
   "source": [
    "print(len(y_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "new_len = len(y_encoded)//5\n",
    "y_train = np.array([[0]*3]*new_len)\n",
    "for i in range(new_len):\n",
    "    idx= i*5\n",
    "    select_mid = idx+2 #(select the middle of the 5 4-second epochs as the label)\n",
    "    y_train[i] = y_encoded[select_mid]\n",
    "    \n",
    "print(y_train[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_encoded[4:34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12960\n",
      "8640\n"
     ]
    }
   ],
   "source": [
    "y_train_new = y_train[0: len_to_keep]\n",
    "y_cv = y_train[len_to_keep:]\n",
    "y_train_new = y_train_new[len_channels]\n",
    "print(len(y_train))\n",
    "print(len(y_train_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64800\n",
      "34114\n",
      "27133\n",
      "3553\n",
      "1.8995133962596003\n",
      "2.388235727711643\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# figure out good class weights\n",
    "print(len(y))\n",
    "print(len(y[y == 0]))\n",
    "print(len(y[y == 1]))\n",
    "print(len(y[y == 2]))\n",
    "# in percents\n",
    "class_w0 = len(y)/(len(y[y == 0]))\n",
    "class_w1 = len(y)/(len(y[y == 1]))\n",
    "class_w2 = 5\n",
    "print(class_w0)\n",
    "print(class_w1)\n",
    "print(class_w2)\n",
    "class_weight = {0: class_w0, 1: class_w1, 2: class_w2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the pre_trained model\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "pre_trained_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "87/87 [==============================] - 19s 216ms/step - loss: 2.5196 - accuracy: 0.5266 - val_loss: 1.0937 - val_accuracy: 0.5100\n",
      "Epoch 2/10\n",
      "87/87 [==============================] - 18s 210ms/step - loss: 2.5126 - accuracy: 0.5341 - val_loss: 1.0889 - val_accuracy: 0.5100\n",
      "Epoch 3/10\n",
      "87/87 [==============================] - 20s 233ms/step - loss: 2.5058 - accuracy: 0.5341 - val_loss: 1.0844 - val_accuracy: 0.5100\n",
      "Epoch 4/10\n",
      "87/87 [==============================] - 20s 234ms/step - loss: 2.4993 - accuracy: 0.5341 - val_loss: 1.0799 - val_accuracy: 0.5100\n",
      "Epoch 5/10\n",
      "87/87 [==============================] - 18s 206ms/step - loss: 2.4929 - accuracy: 0.5341 - val_loss: 1.0755 - val_accuracy: 0.5100\n",
      "Epoch 6/10\n",
      "87/87 [==============================] - 20s 227ms/step - loss: 2.4867 - accuracy: 0.5341 - val_loss: 1.0711 - val_accuracy: 0.5100\n",
      "Epoch 7/10\n",
      "87/87 [==============================] - 18s 206ms/step - loss: 2.4807 - accuracy: 0.5341 - val_loss: 1.0670 - val_accuracy: 0.5100\n",
      "Epoch 8/10\n",
      "87/87 [==============================] - 20s 228ms/step - loss: 2.4749 - accuracy: 0.5341 - val_loss: 1.0629 - val_accuracy: 0.5100\n",
      "Epoch 9/10\n",
      "87/87 [==============================] - 19s 218ms/step - loss: 2.4693 - accuracy: 0.5341 - val_loss: 1.0589 - val_accuracy: 0.5100\n",
      "Epoch 10/10\n",
      "87/87 [==============================] - 20s 224ms/step - loss: 2.4638 - accuracy: 0.5341 - val_loss: 1.0549 - val_accuracy: 0.5100\n"
     ]
    }
   ],
   "source": [
    "history = pre_trained_model.fit({\"left_signal\": train_sh_channels, \"mid_signal\": train_sh_channels, \"right_signal\": train_sh_emg}, y_train_new, batch_size = 100, epochs = 10, class_weight = class_weight, validation_data = ([cv_channels, cv_channels, cv_emg], y_cv))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8640, 2560, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_sh_channels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8640, 2432)\n"
     ]
    }
   ],
   "source": [
    "print(train_sh_emg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_signal\n",
      "mid_signal\n",
      "right_signal\n",
      "conv1d_36\n",
      "conv1d_40\n",
      "conv1d_44\n",
      "max_pooling1d_18\n",
      "max_pooling1d_20\n",
      "max_pooling1d_22\n",
      "dropout_19\n",
      "dropout_20\n",
      "dropout_21\n",
      "conv1d_37\n",
      "conv1d_41\n",
      "conv1d_45\n",
      "conv1d_38\n",
      "conv1d_42\n",
      "conv1d_46\n",
      "conv1d_39\n",
      "conv1d_43\n",
      "conv1d_47\n",
      "max_pooling1d_19\n",
      "max_pooling1d_21\n",
      "max_pooling1d_23\n",
      "concat_axis\n",
      "flatten_6\n",
      "dense_13\n",
      "************************\n",
      "left_signal\n",
      "mid_signal\n",
      "right_signal\n",
      "conv1d_36\n",
      "conv1d_40\n",
      "conv1d_44\n",
      "max_pooling1d_18\n",
      "max_pooling1d_20\n",
      "max_pooling1d_22\n",
      "dropout_19\n",
      "dropout_20\n",
      "dropout_21\n",
      "conv1d_37\n",
      "conv1d_41\n",
      "conv1d_45\n",
      "conv1d_38\n",
      "conv1d_42\n",
      "conv1d_46\n",
      "conv1d_39\n",
      "conv1d_43\n",
      "conv1d_47\n",
      "max_pooling1d_19\n",
      "max_pooling1d_21\n",
      "max_pooling1d_23\n",
      "concat_axis\n"
     ]
    }
   ],
   "source": [
    "# remove the last two layers (flatten, and dense) and replace it with the fine tuning layer\n",
    "for el in pre_trained_model.layers:\n",
    "    print(el.name)\n",
    "pre_trained_model._layers.pop()\n",
    "pre_trained_model._layers.pop()\n",
    "print('************************')\n",
    "for el in pre_trained_model.layers:\n",
    "    print(el.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1024)\n",
      "(None, 1024)\n",
      "(None, 1024)\n"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/41378461/how-to-use-models-from-keras-applications-for-transfer-learnig/41386444#41386444\n",
    "#new_layer = Dense(10, activation='softmax', name='my_dense')\n",
    "\n",
    "#inp = model.input\n",
    "#out = new_layer(model.layers[-1].output)\n",
    "\n",
    "#model2 = Model(inp, out)\n",
    "\n",
    "inp = pre_trained_model.input\n",
    "\n",
    "\n",
    "s = Dropout(0.5)(pre_trained_model.layers[-1].output)\n",
    "\n",
    "# Left branch (cannot flatten before since LSTM requires input of form (None, x, y) NOT (None, z))\n",
    "sLeft = Bidirectional(LSTM(units = 512, return_sequences = True, activation='tanh'))(s) #https://stackoverflow.com/questions/40331510/how-to-stack-multiple-lstm-in-keras\n",
    "sLeft = Bidirectional(LSTM(units = 512, activation='tanh'))(sLeft)\n",
    "print(sLeft.shape)\n",
    "\n",
    "# Right branch\n",
    "q = Flatten()(s)\n",
    "q = Dense(units = 1024, activation = 'relu')(q)\n",
    "print(q.shape)\n",
    "\n",
    "# combine both 1024-length vectors by adding them\n",
    "q = Add()([q, sLeft])\n",
    "print(q.shape)\n",
    "\n",
    "# now dropout 50% and softmax on 3 output neurons\n",
    "q = Dropout(0.5)(q)\n",
    "q = Dense(3, activation = 'softmax')(q)\n",
    "\n",
    "fine_tuned_model = tf.keras.Model(inputs = inp, outputs = q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the pre_trained model\n",
    "opt2 = tf.keras.optimizers.Adam(learning_rate=1e-6)\n",
    "fine_tuned_model.compile(optimizer=opt2, loss='categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "864/864 [==============================] - 430s 498ms/step - loss: 2.5018 - accuracy: 0.5068 - val_loss: 1.0454 - val_accuracy: 0.5100\n",
      "Epoch 2/20\n",
      "864/864 [==============================] - 416s 481ms/step - loss: 2.3422 - accuracy: 0.5149 - val_loss: 0.8884 - val_accuracy: 0.5100\n",
      "Epoch 3/20\n",
      "864/864 [==============================] - 418s 483ms/step - loss: 2.3027 - accuracy: 0.5139 - val_loss: 0.8837 - val_accuracy: 0.5100\n",
      "Epoch 4/20\n",
      "864/864 [==============================] - 418s 484ms/step - loss: 2.3043 - accuracy: 0.5218 - val_loss: 0.8814 - val_accuracy: 0.5100\n",
      "Epoch 5/20\n",
      "864/864 [==============================] - 425s 492ms/step - loss: 2.3047 - accuracy: 0.5194 - val_loss: 0.8822 - val_accuracy: 0.5100\n",
      "Epoch 6/20\n",
      "864/864 [==============================] - 426s 493ms/step - loss: 2.3011 - accuracy: 0.5189 - val_loss: 0.8882 - val_accuracy: 0.5100\n",
      "Epoch 7/20\n",
      "864/864 [==============================] - 432s 499ms/step - loss: 2.3036 - accuracy: 0.5175 - val_loss: 0.8831 - val_accuracy: 0.5100\n",
      "Epoch 8/20\n",
      "864/864 [==============================] - 430s 498ms/step - loss: 2.3031 - accuracy: 0.5142 - val_loss: 0.8858 - val_accuracy: 0.5100\n",
      "Epoch 9/20\n",
      "864/864 [==============================] - 432s 500ms/step - loss: 2.3023 - accuracy: 0.5196 - val_loss: 0.8831 - val_accuracy: 0.5100\n",
      "Epoch 10/20\n",
      "864/864 [==============================] - 434s 502ms/step - loss: 2.3036 - accuracy: 0.5223 - val_loss: 0.8817 - val_accuracy: 0.5100\n",
      "Epoch 11/20\n",
      "864/864 [==============================] - 433s 501ms/step - loss: 2.3023 - accuracy: 0.5196 - val_loss: 0.8787 - val_accuracy: 0.5100\n",
      "Epoch 12/20\n",
      "864/864 [==============================] - 431s 498ms/step - loss: 2.3050 - accuracy: 0.5199 - val_loss: 0.8825 - val_accuracy: 0.5100\n",
      "Epoch 13/20\n",
      "864/864 [==============================] - 426s 493ms/step - loss: 2.3026 - accuracy: 0.5208 - val_loss: 0.8815 - val_accuracy: 0.5100\n",
      "Epoch 14/20\n",
      "864/864 [==============================] - 422s 489ms/step - loss: 2.3038 - accuracy: 0.5199 - val_loss: 0.8862 - val_accuracy: 0.5100\n",
      "Epoch 15/20\n",
      "864/864 [==============================] - 422s 489ms/step - loss: 2.3038 - accuracy: 0.5208 - val_loss: 0.8867 - val_accuracy: 0.5100\n",
      "Epoch 16/20\n",
      "864/864 [==============================] - 430s 497ms/step - loss: 2.3049 - accuracy: 0.5186 - val_loss: 0.8838 - val_accuracy: 0.5100\n",
      "Epoch 17/20\n",
      "864/864 [==============================] - 425s 492ms/step - loss: 2.3042 - accuracy: 0.5191 - val_loss: 0.8869 - val_accuracy: 0.5100\n",
      "Epoch 18/20\n",
      "864/864 [==============================] - 426s 493ms/step - loss: 2.3039 - accuracy: 0.5185 - val_loss: 0.8790 - val_accuracy: 0.5100\n",
      "Epoch 19/20\n",
      "864/864 [==============================] - 425s 492ms/step - loss: 2.3047 - accuracy: 0.5183 - val_loss: 0.8780 - val_accuracy: 0.5100\n",
      "Epoch 20/20\n",
      "864/864 [==============================] - 428s 495ms/step - loss: 2.3034 - accuracy: 0.5250 - val_loss: 0.8833 - val_accuracy: 0.5100\n"
     ]
    }
   ],
   "source": [
    "history2 = fine_tuned_model.fit({\"left_signal\": train_sh_channels, \"mid_signal\": train_sh_channels, \"right_signal\": train_sh_emg}, y_train_new, batch_size = 10, epochs = 20, class_weight = class_weight, validation_data = ([cv_channels, cv_channels, cv_emg], y_cv))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenth = len(eeg1_t)\n",
    "\n",
    "eeg1_reshaped_t = np.array([[0]*2560]*lenth)\n",
    "eeg2_reshaped_t = np.array([[0]*2560]*lenth)\n",
    "emg_reshaped_t = np.array([[0]*2560]*lenth)\n",
    "\n",
    "eeg1_reshaped_t, eeg2_reshaped_t, emg_reshaped_t = reshape_sig(eeg1_t, eeg2_t, emg_t)\n",
    "    \n",
    "rms_vals_t= np.apply_along_axis(rms_transform, axis = 1, arr = emg_reshaped_t)\n",
    "eegs_comb_t = np.hstack((eeg1_reshaped_t, eeg2_reshaped_t))\n",
    "print(eegs_comb_t.shape)\n",
    "def combine_channels(signals):\n",
    "    sigs = np.split(signals, 2)\n",
    "    eeg1 = sigs[0]\n",
    "    eeg2 = sigs[1]\n",
    "    return np.array((eeg1, eeg2)).T\n",
    "    \n",
    "channels_t = np.apply_along_axis(combine_channels, axis = 1, arr = eegs_comb_t)\n",
    "X_pred = [channels_t, channels_t, rms_vals_t]\n",
    "prediction = model.predict(X_pred)\n",
    "dfPredictions = pd.DataFrame(prediction)\n",
    "dfPredictions.index.name = \"id\"\n",
    "dfPredictions.to_csv(\"task4MCSleepNetPredictions.csv\", header = ['y'], index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
