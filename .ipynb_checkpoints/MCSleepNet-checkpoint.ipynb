{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from pywt import wavedec\n",
    "from pywt import waverec\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import pywt\n",
    "import scipy\n",
    "#from keras.utils import plot_model #plot_model(model, to_file='model.png')\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "import pylab as pl\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Input, Add, Flatten, Concatenate, MaxPool1D, Conv1D, Bidirectional, LSTM, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg1 = pd.read_csv(\"train_eeg1.csv\").iloc[:, 1:]\n",
    "eeg2 = pd.read_csv(\"train_eeg2.csv\").iloc[:, 1:]\n",
    "emg = pd.read_csv(\"train_emg.csv\").iloc[:, 1:]\n",
    "df_y = pd.read_csv(\"train_labels.csv\").iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing by sampling with replacement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to pool all the under-represented REM 4-second signals together, then construct new examples as follows:\n",
    "\n",
    "1) For the 1st sample, randomly select a signal and choose its 1st sample as the newly constructed signal's 1st sample\n",
    "\n",
    "...\n",
    "\n",
    "512) For the 512th sample, randomly select a signal and choose its 512th sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg1np = eeg1.values\n",
    "eeg2np = eeg2.values\n",
    "emgnp = emg.values\n",
    "ynp = df_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(eeg2np[0])) 512\n",
    "#rem_indices = np.where(ynp == 3)[0]\n",
    "#print(len(rem_indices)) 3553\n",
    "#print(len(ynp))  64800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg1_aug = []\n",
    "eeg2_aug = []\n",
    "emg_aug  = []\n",
    "\n",
    "# approximately 6 percent of the total number of epochs, 64800, are REM in order to make them \n",
    "def samp_with_replacement(nbr_samples, class_lab):\n",
    "    class_idxs = np.where(ynp == class_lab)[0]\n",
    "    eeg1_f = eeg1np[class_idxs]\n",
    "    eeg2_f = eeg2np[class_idxs]\n",
    "    emg_f  = emgnp[class_idxs]\n",
    "    \n",
    "    # get the columns so we sample from them\n",
    "    eeg1np_t = eeg1_f.T   # has 512 rows\n",
    "    eeg2np_t = eeg2_f.T  # has 512 rows\n",
    "    emgnp_t = emg_f.T   # has 512 rows\n",
    "    \n",
    "    samples_eeg1 = np.array([[0]*512]*nbr_samples)\n",
    "    samples_eeg2 = np.array([[0]*512]*nbr_samples)\n",
    "    samples_emg =  np.array([[0]*512]*nbr_samples)\n",
    "    \n",
    "    for i in range(512):\n",
    "        samples_eeg1[:,i] = resample(eeg1np_t[i], replace=True, n_samples=nbr_samples, random_state=1)\n",
    "        samples_eeg2[:,i] = resample(eeg2np_t[i], replace=True, n_samples=nbr_samples, random_state=2)\n",
    "        samples_emg[:, i]  = resample(emgnp_t[i], replace=True,  n_samples=nbr_samples, random_state=3)\n",
    "    \n",
    "    global eeg1_aug, eeg2_aug, emg_aug\n",
    "    eeg1_aug = np.vstack((eeg1np, samples_eeg1))\n",
    "    eeg2_aug = np.vstack((eeg2np, samples_eeg2))\n",
    "    emg_aug  = np.vstack((emgnp, samples_emg))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_with_replacement(10000, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(eeg1_aug)) 74800\n",
    "#print(len(eeg1np))  64800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Under-sample NREM and Wake classes\n",
    "According to https://arxiv.org/pdf/1809.08443.pdf, the rebalancing was done such that REM was roughly 25% (instead of 5% originally), NREM was 33% and finally 42% from Wake. This leads to the equations\n",
    "\n",
    "1) 13,553/(74,800 - x - y) = 0.25\n",
    "\n",
    "2) (27,133-y)/(74,800 - x - y) = 0.33\n",
    "\n",
    "3) (34,114-x)/(74,800 - x - y) = 0.42 (redundant)\n",
    "\n",
    "which leads to x = 11345 (i.e. reduce Wake by 11345 signals) and y = 9,243 which means Wake has now 22,769 signals, and NREM has 17,890 signals out of 54,212 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_aug = np.append(ynp, np.array([3]*10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74800, 1536)\n"
     ]
    }
   ],
   "source": [
    "under = RandomUnderSampler(sampling_strategy={1: 22769, 2:18890})   # technically this would give 34% for class NREM\n",
    "# stack them horizontally then unstack later by slicing\n",
    "X_new = np.hstack((eeg1_aug, eeg2_aug, emg_aug))\n",
    "print(X_new.shape)\n",
    "X_balanced, y_balanced = under.fit_resample(X_new, y_aug) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 20 seconds segments by combining 5 of the 4-second length segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55210\n"
     ]
    }
   ],
   "source": [
    "## split them again\n",
    "X_balanced = X_balanced[:-2, :]\n",
    "print(len(X_balanced)) # to make sure length is multiple of 5\n",
    "eeg1_bal = X_balanced[:, 0:512] \n",
    "eeg2_bal = X_balanced[:, 512:1024]\n",
    "emg_bal  = X_balanced[:, 1024:1536]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg1_reshaped = np.array([[0]*2560]*11042)\n",
    "eeg2_reshaped = np.array([[0]*2560]*11042)\n",
    "emg_reshaped = np.array([[0]*2560]*11042)\n",
    "for m in range(11042):  # 11,042 = 55210/5 minus since end will do m + 1 (may cause out of bounds exc.)\n",
    "    start = m*5\n",
    "    end = m*5 + 5\n",
    "    combined1 = ((eeg1_bal[start:end, :]).reshape(1, 2560))[0]\n",
    "    combined2 = ((eeg2_bal[start:end, :]).reshape(1, 2560))[0]\n",
    "    combined3 = ((emg_bal[start:end, :]).reshape(1, 2560))[0]\n",
    "    eeg1_reshaped[m] = combined1\n",
    "    eeg2_reshaped[m] = combined2\n",
    "    emg_reshaped[m] = combined3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMS filter of the EMG signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_rms(a, window_size):\n",
    "  a2 = np.power(a,2)\n",
    "  window = 1.0*np.ones(window_size)\n",
    "  return np.sqrt(np.convolve(a2, window, 'valid'))/float(window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11042, 2560)\n"
     ]
    }
   ],
   "source": [
    "#rms_vals = np.array([[0]*20]*11042)    # window size is 1 second = 128 samples in each window\n",
    "print(emg_reshaped.shape)\n",
    "def rms_transform(row):\n",
    "    res = np.array([])\n",
    "    end = len(row)\n",
    "    for i in range(end - 128):\n",
    "        window = row[i:(i + 128)]\n",
    "        temp = window_rms(window, 128)\n",
    "        res = np.append(res, temp)\n",
    "    return res\n",
    "rms_vals= np.apply_along_axis(rms_transform, axis = 1, arr = emg_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11042, 2432)\n"
     ]
    }
   ],
   "source": [
    "print(rms_vals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is not needed anymore\n",
    "# for some reason there is a third dimension, to remove it:\n",
    "#rms_vals = rms_vals[:, :, 0]\n",
    "#print(rms_vals.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine EEG channels\n",
    "so the rows of a matrix are actually two arrays corresponding to EEG1 and EEG2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11042, 5120)\n",
      "(11042, 2560, 2)\n"
     ]
    }
   ],
   "source": [
    "eegs_comb = np.hstack((eeg1_reshaped, eeg2_reshaped))\n",
    "print(eegs_comb.shape)\n",
    "def combine_channels(signals):\n",
    "    sigs = np.split(signals, 2)\n",
    "    eeg1 = sigs[0]\n",
    "    eeg2 = sigs[1]\n",
    "    return np.array((eeg1, eeg2)).T\n",
    "    \n",
    "channels = np.apply_along_axis(combine_channels, axis = 1, arr = eegs_comb)\n",
    "print(channels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction - Model left branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 13, 128)\n"
     ]
    }
   ],
   "source": [
    "signal_left = Input(shape = (2560, 2))\n",
    "def left_branch_model():\n",
    "    x = Conv1D(filters = 64, kernel_size = 50,  strides = 6, activation='relu')(signal_left)\n",
    "    x = MaxPool1D(pool_size=8, strides=8)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 8, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 8, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 8, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = MaxPool1D(pool_size=4, strides=4)(x)\n",
    "    print(x.shape)\n",
    "    return x #tf.keras.Model(inputs = signal, outputs = x)\n",
    "lbranch = left_branch_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction - Model middle branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 3, 128)\n"
     ]
    }
   ],
   "source": [
    "signal_mid = Input(shape = (2560, 2))\n",
    "def mid_branch_model():\n",
    "    x = Conv1D(filters = 64, kernel_size = 500,  strides = 50, activation='relu', padding = 'same')(signal_mid) # try with and without padding = 'same'\n",
    "    x = MaxPool1D(pool_size=8, strides=8)(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(x)\n",
    "    x = MaxPool1D(pool_size=2, strides=2)(x)\n",
    "    print(x.shape)\n",
    "    return x #tf.keras.Model(inputs = signal, outputs = x)\n",
    "mbranch = mid_branch_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction - Model right branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 6, 128)\n"
     ]
    }
   ],
   "source": [
    "signal_right = Input(shape=(2432, 1))\n",
    "def right_branch_model():\n",
    "    z = Conv1D(filters = 64, kernel_size = 500,  strides = 50, activation='relu', padding = 'same')(signal_right)\n",
    "    z = MaxPool1D(pool_size=4, strides=4)(z)\n",
    "    z = Dropout(0.5)(z)\n",
    "    z = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(z)\n",
    "    z = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(z)\n",
    "    z = Conv1D(filters = 128, kernel_size = 6, strides = 1, activation = 'relu', padding = 'same')(z)\n",
    "    z = MaxPool1D(pool_size=2, strides=2)(z)\n",
    "    print(z.shape)\n",
    "    return z #tf.keras.Model(inputs = signal, outputs = z)\n",
    "rbranch = right_branch_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate along the second dimension (of sizes 13, 3, 6 respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 22, 128)\n"
     ]
    }
   ],
   "source": [
    "concat_layer = Concatenate(axis = 1)([lbranch, mbranch, rbranch])\n",
    "print(concat_layer.shape)\n",
    "#concat_model = tf.keras.Model(inputs = [lbranch.input, mbranch.input, rbranch.input], outputs = concat_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1024)\n",
      "(None, 1024)\n",
      "(None, 1024)\n"
     ]
    }
   ],
   "source": [
    "s = Dropout(0.5)(concat_layer)\n",
    "\n",
    "# Left branch (cannot flatten before since LSTM requires input of form (None, x, y) NOT (None, z))\n",
    "sLeft = Bidirectional(LSTM(units = 512, return_sequences = True, activation='tanh'))(s) #https://stackoverflow.com/questions/40331510/how-to-stack-multiple-lstm-in-keras\n",
    "sLeft = Bidirectional(LSTM(units = 512, activation='tanh'))(sLeft)\n",
    "print(sLeft.shape)\n",
    "\n",
    "# Right branch\n",
    "q = Flatten()(s)\n",
    "q = Dense(units = 1024, activation = 'relu')(q)\n",
    "print(q.shape)\n",
    "\n",
    "# combine both 1024-length vectors by adding them\n",
    "q = Add()([q, sLeft])\n",
    "print(q.shape)\n",
    "\n",
    "# now dropout 50% and softmax on 3 output neurons\n",
    "q = Dropout(0.5)(q)\n",
    "q = Dense(3, activation = 'softmax')(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs = [signal_left, signal_mid, signal_right], outputs = q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55212\n",
      "55210\n"
     ]
    }
   ],
   "source": [
    "# use 1,100 samples for cross-validating (about 10%)\n",
    "X_train = [channels, channels, rms_vals]\n",
    "#X_cv = [channels[9942:], channels[9942:], rms_vals[9942:]]\n",
    "y_balanced_ = y_balanced[:-2]\n",
    "\n",
    "print(len(y_balanced))\n",
    "print(len(X_balanced))\n",
    "\n",
    "y_train = np.array([0]*11042)\n",
    "for i in range(11042):\n",
    "    idx= i*5\n",
    "    select_mid = idx+2 #(select the middle of the 5 4-second epochs as the label)\n",
    "    y_train[i] = y_balanced_[select_mid]\n",
    "    \n",
    "#y_cv = y_train[9942:]\n",
    "#y_train = y_train[0:9942]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "994/994 [==============================] - 459s 462ms/step - loss: 1.0450 - accuracy: 0.4173 - val_loss: 1.6767 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/15\n",
      "994/994 [==============================] - 449s 452ms/step - loss: 1.0403 - accuracy: 0.4326 - val_loss: 1.7403 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/15\n",
      "419/994 [===========>..................] - ETA: 4:16 - loss: 1.0340 - accuracy: 0.4399"
     ]
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-6)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "y_train_ = y_train - 1\n",
    "history = model.fit(X_train, y_train_, batch_size = 10, epochs = 50, validation_split = 0.1, shuffle = True) # epochs specified as 10 to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict \n",
    "# { 'acc': [0.9843952109499714],\n",
    "#  'loss': [0.050826362343496051],\n",
    "#  'val_acc': [0.98403786838658314],\n",
    "#  'val_loss': [0.0502210383056177]\n",
    "# }\n",
    "def saveResults():\n",
    "    f = open(\"task4_history.txt\", \"a\")\n",
    "    f.write(\" acc \"+ str(history.history['acc']))\n",
    "    f.write(\"\\n loss \"+ str(history.history['loss']))\n",
    "    f.write(\"\\n val_acc \"+ str(history.history['val_acc']))\n",
    "    f.write(\"\\n val_loss \"+ str(history.history['val_loss']))\n",
    "    f.close()\n",
    "    \n",
    "saveResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the test data and predict\n",
    "eeg1_t = pd.read_csv(\"test_eeg1.csv\").iloc[:, 1:].values\n",
    "eeg2_t = pd.read_csv(\"test_eeg2.csv\").iloc[:, 1:].values\n",
    "emg_t = pd.read_csv(\"test_emg.csv\").iloc[:, 1:].values\n",
    "lenth = len(eeg1)\n",
    "\n",
    "eeg1_reshaped_t = np.array([[0]*2560]*lenth)\n",
    "eeg2_reshaped_t = np.array([[0]*2560]*lenth)\n",
    "emg_reshaped_t = np.array([[0]*2560]*lenth)\n",
    "for m in range(lenth):  # 11,042 = 55210/5 minus since end will do m + 1 (may cause out of bounds exc.)\n",
    "    start = m*5\n",
    "    end = m*5 + 5\n",
    "    combined1 = ((eeg1_t[start:end, :]).reshape(1, 2560))[0]\n",
    "    combined2 = ((eeg2_t[start:end, :]).reshape(1, 2560))[0]\n",
    "    combined3 = ((emg_t[start:end, :]).reshape(1, 2560))[0]\n",
    "    eeg1_reshaped_t[m] = combined1\n",
    "    eeg2_reshaped_t[m] = combined2\n",
    "    emg_reshaped_t[m] = combined3\n",
    "    \n",
    "rms_vals_t= np.apply_along_axis(rms_transform, axis = 1, arr = emg_reshaped_t)\n",
    "eegs_comb_t = np.hstack((eeg1_reshaped_t, eeg2_reshaped_t))\n",
    "print(eegs_comb_t.shape)\n",
    "def combine_channels(signals):\n",
    "    sigs = np.split(signals, 2)\n",
    "    eeg1 = sigs[0]\n",
    "    eeg2 = sigs[1]\n",
    "    return np.array((eeg1, eeg2)).T\n",
    "    \n",
    "channels_t = np.apply_along_axis(combine_channels, axis = 1, arr = eegs_comb_t)\n",
    "X_pred = [channels_t, channels_t, rms_vals_t]\n",
    "prediction = model.predict(X_pred) + 1\n",
    "dfPredictions = pd.DataFrame(prediction)\n",
    "dfPredictions.index.name = \"id\"\n",
    "dfPredictions.to_csv(\"task4MCSleepNetPredictions.csv\", header = ['y'], index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
