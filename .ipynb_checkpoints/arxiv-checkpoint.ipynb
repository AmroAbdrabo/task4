{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from biosppy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>...</th>\n",
       "      <th>x503</th>\n",
       "      <th>x504</th>\n",
       "      <th>x505</th>\n",
       "      <th>x506</th>\n",
       "      <th>x507</th>\n",
       "      <th>x508</th>\n",
       "      <th>x509</th>\n",
       "      <th>x510</th>\n",
       "      <th>x511</th>\n",
       "      <th>x512</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.00016</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.00031</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.00019</td>\n",
       "      <td>-0.000072</td>\n",
       "      <td>-0.00007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000086</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>-0.000390</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>-0.00032</td>\n",
       "      <td>-0.00021</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.00028</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>-0.00034</td>\n",
       "      <td>-0.000960</td>\n",
       "      <td>-0.00120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.00066</td>\n",
       "      <td>0.00088</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.000410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000160</td>\n",
       "      <td>-0.000210</td>\n",
       "      <td>-0.000840</td>\n",
       "      <td>-0.00120</td>\n",
       "      <td>-0.001200</td>\n",
       "      <td>-0.00140</td>\n",
       "      <td>-0.001400</td>\n",
       "      <td>-0.00091</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>-0.00027</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000680</td>\n",
       "      <td>-0.000880</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>-0.000770</td>\n",
       "      <td>-0.000680</td>\n",
       "      <td>-0.00073</td>\n",
       "      <td>-0.00073</td>\n",
       "      <td>-0.00062</td>\n",
       "      <td>-0.000550</td>\n",
       "      <td>-0.000540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000140</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.00043</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.00023</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.00022</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.00022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.000260</td>\n",
       "      <td>-0.00058</td>\n",
       "      <td>-0.00075</td>\n",
       "      <td>-0.00110</td>\n",
       "      <td>-0.001200</td>\n",
       "      <td>-0.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.001100</td>\n",
       "      <td>-0.000790</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>-0.00014</td>\n",
       "      <td>-0.000430</td>\n",
       "      <td>-0.00053</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>-0.00041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.00016</td>\n",
       "      <td>-0.00023</td>\n",
       "      <td>-0.00023</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.000810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          x1        x2        x3       x4        x5       x6        x7  \\\n",
       "Id                                                                       \n",
       "0   0.000400  0.000470  0.000067 -0.00016 -0.000003  0.00031  0.000360   \n",
       "1   0.000067  0.000095  0.000270  0.00028  0.000250  0.00012  0.000094   \n",
       "2   0.000160 -0.000210 -0.000840 -0.00120 -0.001200 -0.00140 -0.001400   \n",
       "3  -0.000140  0.000260  0.000390  0.00043  0.000280  0.00023  0.000390   \n",
       "4  -0.001100 -0.000790 -0.000081  0.00014  0.000200 -0.00014 -0.000430   \n",
       "\n",
       "         x8        x9      x10  ...      x503      x504      x505      x506  \\\n",
       "Id                              ...                                           \n",
       "0   0.00019 -0.000072 -0.00007  ... -0.000086  0.000033 -0.000046 -0.000270   \n",
       "1  -0.00034 -0.000960 -0.00120  ...  0.000046  0.000300  0.000630  0.000710   \n",
       "2  -0.00091 -0.000600 -0.00027  ... -0.000680 -0.000880 -0.001000 -0.000770   \n",
       "3   0.00022  0.000150  0.00022  ...  0.000720  0.000760  0.000380  0.000052   \n",
       "4  -0.00053 -0.000580 -0.00041  ...  0.000290  0.000600  0.000670  0.000190   \n",
       "\n",
       "        x507     x508     x509     x510      x511      x512  \n",
       "Id                                                           \n",
       "0  -0.000390 -0.00034 -0.00032 -0.00021  0.000042  0.000053  \n",
       "1   0.000520  0.00041  0.00066  0.00088  0.000770  0.000410  \n",
       "2  -0.000680 -0.00073 -0.00073 -0.00062 -0.000550 -0.000540  \n",
       "3  -0.000260 -0.00058 -0.00075 -0.00110 -0.001200 -0.001200  \n",
       "4  -0.000055 -0.00016 -0.00023 -0.00023 -0.000330 -0.000810  \n",
       "\n",
       "[5 rows x 512 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eeg1 = pd.read_csv(\"train_eeg1.csv\", index_col='Id')\n",
    "eeg2 = pd.read_csv(\"train_eeg2.csv\", index_col='Id')\n",
    "emg = pd.read_csv(\"train_emg.csv\", index_col='Id')\n",
    "df_y = pd.read_csv(\"train_labels.csv\", index_col='Id')\n",
    "\n",
    "eeg1_t = pd.read_csv(\"test_eeg1.csv\", index_col='Id')\n",
    "eeg2_t = pd.read_csv(\"test_eeg2.csv\", index_col='Id')\n",
    "emg_t = pd.read_csv(\"test_emg.csv\", index_col='Id')\n",
    "\n",
    "eeg1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Butterworth low-pass filter with cutoff at 25.6 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sig(signal):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 34114, 2: 27133, 3: 3553})\n",
      "Counter({3: 34114, 1: 34114, 2: 27133})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# convert to np arrays\n",
    "np_eeg1 = np.array(eeg1)\n",
    "np_eeg2 = np.array(eeg2)\n",
    "np_emg = np.array(emg)\n",
    "np_y = np.ravel(np.array(df_y))\n",
    "\n",
    "np_eeg1_t = np.array(eeg1_t)\n",
    "np_eeg2_t = np.array(eeg2_t)\n",
    "np_emg_t = np.array(emg_t)\n",
    "\n",
    "counter = Counter(np_y)\n",
    "print(counter)\n",
    "\n",
    "# upsample REM class (class 3) using resampling with replacement, while maintaining temporal consistency\n",
    "rem_indices = [idx for idx, label in enumerate(np_y) if label == 3]\n",
    "indices_to_resample = np.random.choice(rem_indices, size=counter[1] - counter[3])\n",
    "\n",
    "repetitions = []\n",
    "for i in range(len(np_y)):\n",
    "    occurrences = np.count_nonzero(indices_to_resample == i)\n",
    "    if (occurrences > 0):\n",
    "        # resampling this index, so add it to repetitions (adding 1 to count the original)\n",
    "        repetitions.append(occurrences + 1)\n",
    "    else:\n",
    "        # not resampling this index, so the repetition will only be 1 (i.e. it won't be duplicated)\n",
    "        repetitions.append(1)\n",
    "\n",
    "eeg1_res = np.repeat(np_eeg1, repeats=repetitions, axis=0)\n",
    "eeg2_res = np.repeat(np_eeg2, repeats=repetitions, axis=0)\n",
    "emg_res = np.repeat(np_emg, repeats=repetitions, axis=0)\n",
    "y_res = np.repeat(np_y, repeats=repetitions, axis=0)\n",
    "\n",
    "counter = Counter(y_res)\n",
    "print(counter)\n",
    "\n",
    "np_eeg1, np_eeg2, np_emg, np_y = eeg1_res, eeg2_res, emg_res, y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data by concatenating data from 5 consecutive epochs together (use \"padding\" for epochs at start and end)\n",
    "\n",
    "def concat_epochs(eeg1, eeg2, emg):\n",
    "    num_epochs = len(eeg1)\n",
    "    \n",
    "    eeg1_transformed = []\n",
    "    eeg2_transformed = []\n",
    "    emg_transformed = []\n",
    "    \n",
    "    for i in range(0, num_epochs):\n",
    "        if i == 0:\n",
    "            epoch1, epoch2, epoch3, epoch4, epoch5 = 0, 0, 0, 1, 2\n",
    "        elif i == 1:\n",
    "            epoch1, epoch2, epoch3, epoch4, epoch5 = 0, 0, 1, 2, 3\n",
    "        elif i == num_epochs - 2:\n",
    "            epoch1, epoch2, epoch3, epoch4, epoch5 = i-2, i-1, i, i+1, i+1\n",
    "        elif i == num_epochs - 1:\n",
    "            epoch1, epoch2, epoch3, epoch4, epoch5 = i-2, i-1, i, i, i\n",
    "        else:\n",
    "            epoch1, epoch2, epoch3, epoch4, epoch5 = i-2, i-1, i, i+1, i+2\n",
    "        \n",
    "        eeg1_epochs = np.concatenate((eeg1[epoch1], eeg1[epoch2], eeg1[epoch3], eeg1[epoch4], eeg1[epoch5]))\n",
    "        eeg1_transformed.append(eeg1_epochs)\n",
    "    \n",
    "        eeg2_epochs = np.concatenate((eeg2[epoch1], eeg2[epoch2], eeg2[epoch3], eeg2[epoch4], eeg2[epoch5]))\n",
    "        eeg2_transformed.append(eeg2_epochs)\n",
    "    \n",
    "        emg_epochs = np.concatenate((emg[epoch1], emg[epoch2], emg[epoch3], emg[epoch4], emg[epoch5]))\n",
    "        emg_transformed.append(emg_epochs)\n",
    "    \n",
    "    return np.array(eeg1_transformed), np.array(eeg2_transformed), np.array(emg_transformed)\n",
    "\n",
    "eeg1_transf, eeg2_transf, emg_transf = concat_epochs(np_eeg1, np_eeg2, np_emg)  \n",
    "np_eeg1, np_eeg2, np_emg = eeg1_transf, eeg2_transf, emg_transf\n",
    "\n",
    "print(\"np_eeg1.shape: {}\".format(np_eeg1.shape)) # should be (95361, (512 x 5)) = (95361, 2560)\n",
    "print(\"np_eeg2.shape: {}\".format(np_eeg2.shape)) # should be (95361, (512 x 5)) = (95361, 2560)\n",
    "print(\"np_emg.shape: {}\".format(np_emg.shape)) # should be (95361, (512 x 5)) = (95361, 2560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, losses, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from winsound import Beep\n",
    "\n",
    "# decrement each label by 1 to fit with sparse categorical cross entropy - we then increment the label by 1 in the predictions\n",
    "# i.e. we train on labels [0, 1, 2], which map to [1, 2, 3] in our predictions\n",
    "y_dec = [label - 1 for label in np_y]\n",
    "np_y = np.array(y_dec)\n",
    "\n",
    "eeg1_train, eeg1_validation, y_train, y_validation = train_test_split(np_eeg1, np_y, test_size=0.33, shuffle=False)\n",
    "eeg2_train, eeg2_validation, _, _ = train_test_split(np_eeg2, np_y, test_size=0.33, shuffle=False)\n",
    "emg_train, emg_validation, _, _ = train_test_split(np_emg, np_y, test_size=0.33, shuffle=False)\n",
    "\n",
    "X_train = np.dstack((eeg1_train, eeg2_train, emg_train))\n",
    "print(\"X_train.shape: {}\".format(X_train.shape))\n",
    "\n",
    "X_validation = np.dstack((eeg1_validation, eeg2_validation, emg_validation))\n",
    "print(\"X_validation.shape: {}\".format(X_validation.shape))\n",
    "\n",
    "# neural net\n",
    "model = models.Sequential()\n",
    "model.add(layers.BatchNormalization())\n",
    "# try with 128 filters (to match sampling frequency)\n",
    "model.add(layers.Conv1D(filters=128, kernel_size=(5,), strides=1, activation='relu')) # layer 1\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv1D(filters=128, kernel_size=(5,), strides=2, activation='relu')) # layer 2\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv1D(filters=128, kernel_size=(5,), strides=1, activation='relu')) # layer 3\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv1D(filters=128, kernel_size=(5,), strides=2, activation='relu')) # layer 4\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv1D(filters=128, kernel_size=(5,), strides=1, activation='relu')) # layer 5\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv1D(filters=128, kernel_size=(5,), strides=2, activation='relu')) # layer 6\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv1D(filters=128, kernel_size=(5,), strides=1, activation='relu')) # layer 7\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Conv1D(filters=128, kernel_size=(5,), strides=2, activation='relu')) # layer 8\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.2, input_shape=(128,)))\n",
    "model.add(layers.Dense(80, activation='relu')) # layer 9, fc1\n",
    "model.add(layers.Dense(3, activation='softmax')) # layer 10, fc2\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=256)\n",
    "\n",
    "model.evaluate(X_validation, y_validation, verbose=2)\n",
    "\n",
    "Beep(1000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply concatenation transformation to test data\n",
    "eeg1_t_transf, eeg2_t_transf, emg_t_transf = concat_epochs(np_eeg1_t, np_eeg2_t, np_emg_t)  \n",
    "np_eeg1_t, np_eeg2_t, np_emg_t = eeg1_t_transf, eeg2_t_transf, emg_t_transf\n",
    "\n",
    "X_test = np.dstack((np_eeg1_t, np_eeg2_t, np_emg_t))\n",
    "print(\"X_test.shape: {}\".format(X_test.shape))\n",
    "\n",
    "# predict\n",
    "predictions = model.predict(X_test)\n",
    "print(predictions)\n",
    "result = []\n",
    "for prediction_probs in predictions:\n",
    "    idx = np.argmax(prediction_probs)\n",
    "    result.append(idx + 1)\n",
    "result = np.transpose(np.array(result))\n",
    "\n",
    "df_r = pd.DataFrame(result, index=eeg1_t.index.astype(int))\n",
    "df_out = pd.concat([df_r], axis=1, sort=False)\n",
    "df_out.columns = df_y.columns\n",
    "\n",
    "df_out.to_csv('preds.csv', index=True, header=True, float_format='%.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
